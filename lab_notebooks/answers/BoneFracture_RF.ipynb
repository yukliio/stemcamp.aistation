{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukliio/stemcamp.aistation/blob/main/lab_notebooks/answers/BoneFracture_RF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5M7t5a5GXo2"
      },
      "source": [
        "## Problem Statement: üß† Using AI to Help Doctors Spot Bone Fractures ü§ñ\n",
        "\n",
        "In small towns and villages, doctors may not have high-tech machines or strong internet. They need a smart, easy-to-use tool that can help them detect bone fractures just by looking at MRI scans ‚Äî no X-rays needed!\n",
        "\n",
        "### üí° What This Tool Does:\n",
        "- Uses a **Random Forest** model üå≥ to study MRI images.\n",
        "- Analyzes scans of bones to figure out whether there's a fracture.\n",
        "\n",
        "### üß™ What It Should Predict:\n",
        "Whether a bone is **fractured** or **not fractured**.\n",
        "\n",
        "### Let's Start Building!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚≠ê Step 0: download our dataset."
      ],
      "metadata": {
        "id": "EPoX1ftz9xoV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "agV1DDUqI2c5",
        "outputId": "6dad22d3-176a-479f-cdec-db40200d7ce0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bae48e2f-7294-4b0f-95e8-229b20019a23\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bae48e2f-7294-4b0f-95e8-229b20019a23\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle (1).json': b'{\"username\":\"yukliio\",\"key\":\"9dc1d69035876ea5287e0c7ce3e46048\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a kaggle folder\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls -al ~/.kaggle"
      ],
      "metadata": {
        "id": "93tsyXNu64MD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "673a400a-07af-4598-c846-825a869098e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‚Äò/root/.kaggle‚Äô: File exists\n",
            "total 16\n",
            "drwxr-xr-x 2 root root 4096 Nov 18 23:31 .\n",
            "drwx------ 1 root root 4096 Nov 18 23:31 ..\n",
            "-rw------- 1 root root   63 Nov 18 23:37 kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mjs5laeaNmFe",
        "outputId": "54f6b48d-b79d-47bf-e612-f1499429ea82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/bmadushanirodrigo/fracture-multi-region-x-ray-data\n",
            "License(s): ODC Public Domain Dedication and Licence (PDDL)\n",
            "Downloading fracture-multi-region-x-ray-data.zip to /content\n",
            " 91% 439M/481M [00:03<00:00, 56.9MB/s]\n",
            "100% 481M/481M [00:03<00:00, 148MB/s] \n",
            "replace fracture-multi-region-x-ray/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/test/fractured/0.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d bmadushanirodrigo/fracture-multi-region-x-ray-data --force\n",
        "!unzip -q fracture-multi-region-x-ray-data.zip -d fracture-multi-region-x-ray\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚≠ê Step 1: Get Our Images Ready üß†üñºÔ∏è\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Before the AI can learn to spot bone fractures, we need to turn the x-ray images into something it can understand ‚Äî numbers!\n",
        "\n",
        "## üõ†Ô∏è What This Code Does:\n",
        "\n",
        "1. **Resize** every image to **128 x 128 pixels** so they all look the same to the computer.\n",
        "2. **Flatten** the images ‚Äî this means we **turn a 2D image into 1 long list of numbers**.\n",
        "   - Computers need everything to be in a straight line (1D), not a grid (2D)!\n",
        "   - Example: If an image is 128x128 pixels, flattening it gives **16,384 numbers** (128 √ó 128).\n",
        "   - [[ 10, 20, 30],\n",
        "      [ 40, 50, 60],\n",
        "      [ 70, 80, 90]] (2D) ---> [10, 20, 30, 40, 50, 60, 70, 80, 90] (Flattened 1D)"
      ],
      "metadata": {
        "id": "E-wzV69x-LZv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuzT2lQPSA5R"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "image_size = (128, 128)  # Resize all images to 64x64\n",
        "\n",
        "def load_and_preprocess(image_folder):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for label_name in os.listdir(image_folder):\n",
        "        label_folder = os.path.join(image_folder, label_name)\n",
        "        for image_file in os.listdir(label_folder):\n",
        "            img_path = os.path.join(label_folder, image_file)\n",
        "            try:\n",
        "              img = Image.open(img_path).convert('L')\n",
        "\n",
        "              # ‚úÇÔ∏è Resize the image to 128 x 128 pixels [WRITE CODE UNDER HERE]!\n",
        "              img = img.resize(image_size)\n",
        "\n",
        "              # üî¢ Turn the image into a big list of numbers (flatten it) [WRITE CODE UNDER HERE]\n",
        "              img_array = np.array(img).resize(image_size)\n",
        "\n",
        "              data.append(img_array)\n",
        "              labels.append(label_name)\n",
        "\n",
        "            except Exception as e:\n",
        "              pass\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "train_dir = \"/content/fracture-multi-region-x-ray/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/train/\"\n",
        "print(\"üì• Loading training images...\")\n",
        "X_train, y_train = load_and_preprocess(train_dir)\n",
        "\n",
        "print(\"‚úÖ X_train shape (images):\", X_train.shape) # the number should be (5712, 16384) since 128 * 128 = 16384!\n",
        "print(\"‚úÖ y_train shape (labels):\", y_train.shape)\n",
        "\n",
        "print(\"üéâ All images are loaded and ready for the AI to learn!\")\n",
        "\n",
        "X_test, y_test = load_and_preprocess('/content/fracture-multi-region-x-ray/Bone_Fracture_Binary_Classification/Bone_Fracture_Binary_Classification/test/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'length of the training set: {len(X_train)}')\n",
        "print(f'length of the testing set: {len(X_test) }')"
      ],
      "metadata": {
        "id": "36P8vsW2f9KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "do_0XhclV4J7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gneZkrZhPO0D"
      },
      "source": [
        "# ‚≠ê Step 2: Preview the X-rays ü©ªüëÄ\n",
        "\n",
        "Let‚Äôs look at 25 random x-ray images from our training data.\n",
        "\n",
        "## üõ†Ô∏è What This Code Does:\n",
        "\n",
        "- Picks random images from the dataset üé≤  \n",
        "- Shows them in a 5√ó5 grid üñºÔ∏è  \n",
        "- Displays the label: **fractured** or **not fractured**\n",
        "\n",
        "A quick check to make sure everything looks good before training! ‚úÖ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkB37c2VOIXw"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(10)\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "\n",
        "# ‚úñÔ∏è Set up a grid to show 25 images [WRITE CODE UNDER HERE]\n",
        "rows, cols = 5,5\n",
        "\n",
        "for i in range(1, rows * cols + 1):\n",
        "    random_index =  random.randint(0, len(X_train))\n",
        "    image = X_train[random_index]\n",
        "    label = y_train[random_index]\n",
        "    fig.add_subplot(rows, cols, i)\n",
        "    plt.imshow(image.reshape(128, 128), cmap=\"gray\")\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚≠ê Step 3: Train the Model üå≥ü§ñ\n",
        "\n",
        "We will use a Random Forest model to learn from the x-rays and spot fractures!\n",
        "\n",
        "---\n",
        "\n",
        "### ü§î What is a Random Forest?\n",
        "\n",
        "A **Random Forest** is a type of AI model made up of many **decision trees**. Think of it like this:\n",
        "\n",
        "- üå≤ Each tree is like a small \"expert\" that makes guesses based on what it sees.\n",
        "- üå≥ When we put lots of trees together, they vote on what the answer should be.\n",
        "- ‚úÖ The final answer is based on the **majority vote** from all the trees ‚Äî like teamwork!\n",
        "\n",
        "This helps the model be more accurate and less likely to get tricked by strange or unusual images.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://miro.medium.com/v2/resize:fit:1280/0*VdemgOqLxWHyJEH3\" width=\"500\"/>\n",
        "</p>"
      ],
      "metadata": {
        "id": "dCnVU7hEBDHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **n_estimators** just means we have **25 trees** to help us make predictions. The more trees, more more decisions the AI will have to make before determining whether the patient has a bone fracture or not."
      ],
      "metadata": {
        "id": "ks2QwPkaG6-y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35RXXdYfYQ0Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "bonefracture_AI = RandomForestClassifier(n_estimators=25, criterion='entropy', random_state =0)\n",
        "\n",
        "# üë©‚Äçüè´ teach the AI based off of our training data [WRITE CODE UNDER HERE]\n",
        "bonefracture_AI.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚≠ê Step 4: Check AI Accuracy ‚úÖüìä\n",
        "We test the AI‚Äôs guesses on new x-rays and see how accurate it is using a confusion matrix.\n",
        "\n",
        "### What‚Äôs a Confusion Matrix? ‚ùì\n",
        "\n",
        "It‚Äôs a chart that helps us see how well our AI is doing by comparing its guesses to the real answers.\n",
        "\n",
        "- ‚úÖ **True Positive (TP):** AI correctly says \"fractured\" when the bone is fractured.\n",
        "- ‚úÖ **True Negative (TN):** AI correctly says \"not fractured\" when the bone is healthy.\n",
        "- ‚ùå **False Positive (FP):** AI says \"fractured\" but the bone is actually healthy.\n",
        "- ‚ùå **False Negative (FN):** AI says \"not fractured\" but the bone is fractured.\n",
        "\n",
        "This helps us understand where the AI gets it right ‚Äî and where it makes mistakes!\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://cdn.prod.website-files.com/660ef16a9e0687d9cc27474a/662c42677529a0f4e97e4f96_644aea65cefe35380f198a5a_class_guide_cm08.png\" width=\"500\"/>\n",
        "</p>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MjuiLFl9BYtv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ofr-P1KYzsG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
        "\n",
        "# Step 1: Make predictions\n",
        "y_pred = bonefracture_AI.predict(X_test)\n",
        "\n",
        "# Step 2: Create confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Step 3: Let's see the  results!\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "print(f\"Accuracy of Random Forest bone fracture detection model: {round(accuracy_score(y_test, y_pred) * 100, 2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚≠ê Step 5: Did Our AI Get It Right?\n",
        "\n",
        "Now that we've trained our AI to detect brain tumors using Random Forest, it's time to test how well it's doing!\n",
        "\n",
        "In this step, we:\n",
        "- Ask the AI to look at brain scans it hasn't seen before\n",
        "- Check how many it got right ‚úÖ\n",
        "- Check how many it got wrong ‚ùå\n",
        "- Show the results in a colorful bar chart!"
      ],
      "metadata": {
        "id": "g846yokyFdG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# üßÆ Make predictions [WRITE CODE UNDER HERE]\n",
        "y_pred = bonefracture_AI.predict(X_test)\n",
        "\n",
        "# Calculate number of correct and wrong predictions\n",
        "correct = sum(y_pred == y_test)\n",
        "wrong = sum(y_pred != y_test)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(['Correct Predictions', 'Wrong Predictions'], [correct, wrong], color=['green', 'red'])\n",
        "plt.title('Random Forest Model Prediction Results')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.ylim(0, len(y_test) + 10)\n",
        "\n",
        "# Show the accuracy as text above the bars\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "plt.text(0, correct + 5, f\"{correct} ({accuracy*100:.2f}%)\", ha='center', color='black', fontsize=12)\n",
        "plt.text(1, wrong + 5, f\"{wrong} ({(1-accuracy)*100:.2f}%)\", ha='center', color='black', fontsize=12)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "21aabETAEUSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚≠ê Step 6: Visualize the AI‚Äôs Predictions üéØü©ª\n",
        "\n",
        "Let‚Äôs look at 25 random x-ray images from the test set and see how well the AI did.\n",
        "\n",
        "- For each image, we show the **true label (T)** and the AI‚Äôs **prediction (P)**.  \n",
        "- If the AI guessed correctly, the title is **green** ‚úÖ.  \n",
        "- If it guessed wrong, the title turns **red** ‚ùå.\n",
        "\n",
        "This helps us quickly spot where the AI is doing great ‚Äî and where it needs improvement."
      ],
      "metadata": {
        "id": "H05B8jNmC2a9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ06NCmseskc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "random.seed(10)\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "rows, cols = 5, 5\n",
        "\n",
        "for i in range(1, rows * cols + 1):\n",
        "    random_index = random.randint(0, len(X_test) - 1)\n",
        "    image = X_test[random_index]\n",
        "    label = y_test[random_index]\n",
        "    prediction = bonefracture_AI.predict(image.reshape(1, -1))[0]\n",
        "\n",
        "    # üíö Set the text green if correct. Otherwise, red [WRITE CODE UNDER HERE]!\n",
        "    color = \"green\" if prediction == label else \"red\"\n",
        "\n",
        "    ax = fig.add_subplot(rows, cols, i)\n",
        "    ax.imshow(image.reshape(128, 128), cmap=\"gray\")\n",
        "    ax.set_title(f\"T:{label}, P:{prediction}\", fontsize=8, color=color)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üéâ Congrats on Completing Your AI Project! üß†ü§ñ\n",
        "\n",
        "Awesome job! You created an AI that can spot bone fractures from x-rays ‚Äî that‚Äôs seriously impressive! üí™"
      ],
      "metadata": {
        "id": "Qw8R2OU_GeBx"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}